{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-doctor",
   "metadata": {},
   "source": [
    "# Adaptive Sampling\n",
    "\n",
    "In this tutorial you will learn:\n",
    "    \n",
    "1. Basic acquisition using RunEngine\n",
    "2. Generating basic acquistion plans for multiple sample enviornments on a simulated diffraction beamline\n",
    "3. How to use the Bluesky Adaptive harness to readly integrate AI-agents with the beamline\n",
    "4. Demonstration of Reinforcement Learning (RL) being used to optimize data collection stradegies\n",
    "\n",
    "\n",
    "For more bluesky tutorials, goto https://try.nsls2.bnl.gov/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-example",
   "metadata": {},
   "source": [
    "<img src=\"BS_layout.png\" alt=\"Bluesky flow diagram\" style=\"width: 600px;\"/>  [(image source)](https://iopscience.iop.org/article/10.1088/2632-2153/abc9fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-saudi",
   "metadata": {},
   "source": [
    "## Some of the software we use:\n",
    "\n",
    "* **Bluesky RunEngine** for experiment orchestration (sequencing)\n",
    "* **Bluesky Ophyd** for device integration (for this demo, a simulated detector)\n",
    "* **Bluesky Widgets** components for live-updating (\"streaming\") visualization\n",
    "* **Matplotlib** for visualization\n",
    "* **Bluesky Adaptive**, an adaptive \"harness\" for integrating an Agent in a feedback loop with the Bluesky RunEngine\n",
    "* **Tensorflow** for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky import RunEngine\n",
    "from bluesky.plans import count\n",
    "from utils.simulated_hardware import detector, sample_selector, select_sample\n",
    "from utils.visualization import stream_to_figures\n",
    "from utils.adaptive_recommendations import with_agent\n",
    "\n",
    "detector.delay = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-bermuda",
   "metadata": {},
   "source": [
    "## Make a \"RunEngine\"\n",
    "\n",
    "* Processes a set of instructions (a \"plan\") from the user\n",
    "* Direct hardware, tracks what is moving when, and tries to clean up correct in the event of success or failures\n",
    "* Emits metadata and data in a streaming fashion for consumers (plots, models, storage, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-rover",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RE = RunEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-bishop",
   "metadata": {},
   "source": [
    "The RunEngine can move this things, and it can take data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-hawaiian",
   "metadata": {},
   "source": [
    "## Acquire some images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-funds",
   "metadata": {},
   "source": [
    "For this tutorial, we will be moving a <code>sample_selector</code> ophyd device, which can switch between samples on our simulated beamline.  We can read the current status of the motor to see which sample we are currently on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_selector.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-blogger",
   "metadata": {},
   "source": [
    "To move this motor, we could use the built-in bluesky <code>mv</code> plan..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky.plan_stubs import mv\n",
    "\n",
    "RE(mv(sample_selector,2))\n",
    "\n",
    "print (sample_selector.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-conducting",
   "metadata": {},
   "source": [
    "Or, we can write our own custom plan with whatever language and extensions we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sample(sample_number):\n",
    "    print ('\\nMoving to sample '+str(sample_number))\n",
    "    yield from mv(sample_selector, sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(select_sample(0))  # This moves a sample positioner to place Sample 0 in the beam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-completion",
   "metadata": {},
   "source": [
    "In this tutorial, we are focused on streaming data formatted in the document-model.  As such, we're going to setup our visualization first, and then stream data in as we are measuring.  \n",
    "\n",
    "Functionally, this involve creating a figure and axes with Matplotlib, and then passing these to a callback function that will digest documents emitted by the RunEngine.\n",
    "\n",
    "When the cell below is first run, you should see a checkerboard pattern and some basic metadata in the title (sample number, and measurment number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(squeeze=False, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-savings",
   "metadata": {},
   "source": [
    "Now we can select the sample we want and pass a <code>count</code> plan into the run engine.   \n",
    "\n",
    "<code>count</code> is the most basic acquisition plan in Bluesky.  It takes as an argument a list of detectors.  In this case, we will pass it both the <code>detector</code> and the `sample_selector` ophyd objects.  In this way, the emitted documents will automatically contain both the image data from the detector and the sample number associated with this data (important metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(select_sample(0))\n",
    "RE(count([sample_selector, detector]), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-channels",
   "metadata": {},
   "source": [
    "If everything worked, you should have seen a pattern automatically appear on the visualization, with the associated sample number (\"Sample 0\") in the image title.  This data is pulled from the streaming documents emitted by the RunEngine - we didn't have to go get them and fully process them later!\n",
    "\n",
    "Note that if you look at the immidiate output of the cell, you should see a long-string of letters and numbers.  This serves as a unique identifier (uuid) for that particular measurment that will never be repeated.  These uuids can be used as book-keeping identifiers for later data lookup, but that is beyond the scope of this tutorial.\n",
    "\n",
    "So, what happens if we measure the same sample again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(count([sample_selector, detector]), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-zoning",
   "metadata": {},
   "source": [
    "The <code>stream_to_figures</code> callback we have setup here contains logic to automatically average additional measurments of the same sample together.  As such, you may have noticed that the image quality improved slightly when this second measurment was performed.  The \"N_shots\" quantity in the plot title also reflects this number of shots on sample increasing.\n",
    "\n",
    "You can try re-running that cell several times if you'd like, but we can expect little visual change.  This is because sample 0 happens to be a 'strong' scatterer, and it's resultant signal-to-noise quality is good over the background.  In fact, even a single exposure produced an image with sufficient contrast to interpret scientifically.\n",
    "\n",
    "Next, let's set up a new figure, move to the next sample, and take a measurment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(squeeze=False, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes, start_at=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(select_sample(1))\n",
    "RE(count([sample_selector, detector]), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-balance",
   "metadata": {},
   "source": [
    "This sample doesn't look nearly as good as the first one! It gives a weak signal (low signal-to-noise ratio). A single exposure does not produce sufficient contrast, but we can take additional exposures. The visualization above will display the average of all the exposures of this sample.\n",
    "\n",
    "We could do that by hand, re-reunning the above cell several times.  Or, we could write a custom plan to do this.  Let's go with the later as it's less tedius to manage.  Plus, we can take advantage of the ability to use plans in other plans!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_count(num_counts):\n",
    "    for i in range(num_counts):\n",
    "        print ('sequence number '+str(i))\n",
    "        yield from count([sample_selector, detector])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-stanford",
   "metadata": {},
   "source": [
    "Note that we didn't have to know anything about how the guts of `count` worked, and we even made the decision to hardcode `detector` and `sample_selector` into the plan (though we wouldn't need to, it's up to how you want to write the plan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_list = RE(multi_count(5), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-scholarship",
   "metadata": {},
   "source": [
    "Now the statistics on that weakly-scattering sample are starting to look better!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-batman",
   "metadata": {},
   "source": [
    "## Acquire images for more than one sample\n",
    "\n",
    "We've already seen that samples 0 and 1 represent a strong and weakly scatterer respectively.  Let's say that based off these initial observations, we decide that the poorly-scattering sample need to be measured by some ratio (e.g. 4x) as often as good scattering samples.  We probably also want to be able to define how many total loops to complete over both samples at the desired measurement ratio.\n",
    "\n",
    "Let's write a plan!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_sample_plan(measure_ratio, tot_loops=1):\n",
    "    for i in range(tot_loops):\n",
    "        print ('\\tNow on big loop '+str(i))\n",
    "        yield from select_sample(0)\n",
    "        yield from count([sample_selector, detector])\n",
    "        yield from select_sample(1)\n",
    "        for i in range(measure_ratio):\n",
    "            yield from count([sample_selector, detector])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-polymer",
   "metadata": {},
   "source": [
    "To make the visualization easier, let's setup a callback that can display both samples at once as the data is streamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, squeeze=False, constrained_layout=True, figsize=(5, 3))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_list = RE(multi_sample_plan(4,tot_loops=2), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-causing",
   "metadata": {},
   "source": [
    "## Dealing with many, many samples.\n",
    "\n",
    "We have thus far been playing with just a couple of samples, but on the real PDF beamline at NSLS-II, we often load hundreds of different samples at one time.  And each of these samples could have very different scattering qualities!\n",
    "\n",
    "<img src=\"multi_bracket.png\" alt=\"PDF High Capacity Sample Changer\" style=\"width: 600px;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-break",
   "metadata": {},
   "source": [
    "## Write a custom Bluesky \"plan\" to sweep samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_sweep(total_shots):\n",
    "    \"Sweep over the samples in order. Take up to `total_shots` shots.\"\n",
    "    for shot in range(total_shots):\n",
    "        yield from select_sample(shot % 9)\n",
    "        yield from count([sample_selector, detector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-baptist",
   "metadata": {},
   "source": [
    "Our simulated detector has a simulated \"delay\", standing in for the exposure and readout time in a real detector. Here we'll make it go faster so the following examples runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.delay = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = RE(sequential_sweep(total_shots=18), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-latex",
   "metadata": {},
   "source": [
    "## Use `bluesky-adaptive` to let an Agent drive the experiment\n",
    "\n",
    "It is have access to the data as it is acquired and use this to decide when to move to the next sample.\n",
    "\n",
    "These particular agents are aware of a \"budget\" of time for this experiment. They aim to make the most efficient use of the available time to obtain high-constrant, interpretable images.\n",
    "\n",
    "### Agent 1: Naive Agent\n",
    "\n",
    "This will do effectively same thing we just did above---sequential sweeps---but it will do so using the `bluesky-adaptive` machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adaptive_recommendations import NaiveAgent\n",
    "\n",
    "unique_ids = RE(\n",
    "    with_agent(NaiveAgent(9), max_shots=70),\n",
    "    callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-status",
   "metadata": {},
   "source": [
    "### Agent 2: Reinforcement Learning Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adaptive_recommendations import RLAgent\n",
    "detector.delay = 1\n",
    "unique_ids = RE(\n",
    "    with_agent(RLAgent(9, 'tf_models/bluesky-tutorial/saved_models'), max_shots=90),\n",
    "    callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-eating",
   "metadata": {},
   "source": [
    "### Agent 3: \"Cheating\" (Omniscient) Agent\n",
    "\n",
    "This agent is told *a priori* which samples are good and which are bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adaptive_recommendations import CheatingAgent\n",
    "\n",
    "unique_ids = RE(\n",
    "    with_agent(CheatingAgent(9), max_shots=50),\n",
    "    callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-biology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
