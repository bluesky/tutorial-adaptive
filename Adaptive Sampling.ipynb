{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooperative-ebony",
   "metadata": {},
   "source": [
    "# Adaptive Sampling\n",
    "\n",
    "In this tutorial you will learn:\n",
    "    \n",
    "1. Basic acquisition using RunEngine\n",
    "2. Generating basic acquistion plans for multiple sample enviornments on a simulated diffraction beamline\n",
    "3. How to use the Bluesky Adaptive harness to readly integrate AI-agents with the beamline\n",
    "4. Demonstration of Reinforcement Learning (RL) being used to optimize data collection stradegies\n",
    "\n",
    "\n",
    "For more bluesky tutorials, goto https://try.nsls2.bnl.gov/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-paraguay",
   "metadata": {},
   "source": [
    "<img src=\"BS_layout.png\" alt=\"Bluesky flow diagram\" style=\"width: 600px;\"/>  [(image source)](https://iopscience.iop.org/article/10.1088/2632-2153/abc9fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-secretary",
   "metadata": {},
   "source": [
    "## Some of the software we use:\n",
    "\n",
    "* **Bluesky RunEngine** for experiment orchestration (sequencing)\n",
    "* **Bluesky Ophyd** for device integration (for this demo, a simulated detector)\n",
    "* **Bluesky Widgets** components for live-updating (\"streaming\") visualization\n",
    "* **Matplotlib** for visualization\n",
    "* **Bluesky Adaptive**, an adaptive \"harness\" for integrating an Agent in a feedback loop with the Bluesky RunEngine\n",
    "* **Tensorflow** for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky import RunEngine\n",
    "from bluesky.plans import count\n",
    "from utils.simulated_hardware import detector, sample_selector, select_sample\n",
    "from utils.visualization import stream_to_figures\n",
    "from utils.adaptive_recommendations import with_agent\n",
    "\n",
    "detector.delay = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-reggae",
   "metadata": {},
   "source": [
    "## Make a \"RunEngine\"\n",
    "\n",
    "* Processes a set of instructions (a \"plan\") from the user\n",
    "* Direct hardware, tracks what is moving when, and tries to clean up correct in the event of success or failures\n",
    "* Emits metadata and data in a streaming fashion for consumers (plots, models, storage, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-ranch",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RE = RunEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-israel",
   "metadata": {},
   "source": [
    "The RunEngine can move this things, and it can take data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-diesel",
   "metadata": {},
   "source": [
    "## Acquire some images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-israeli",
   "metadata": {},
   "source": [
    "For this tutorial, we will be moving a <code>sample_selector</code> ophyd device, which can switch between samples on our simulated beamline.  We can read the current status of the motor to see which sample we are currently on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_selector.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-pollution",
   "metadata": {},
   "source": [
    "To move this motor, we could use the built-in bluesky <code>mv</code> plan..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluesky.plan_stubs import mv\n",
    "\n",
    "RE(mv(sample_selector,2))\n",
    "\n",
    "print (sample_selector.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-circle",
   "metadata": {},
   "source": [
    "Or, we can write our own custom plan with whatever language and extensions we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sample(sample_number, noisy=False):\n",
    "    if noisy:\n",
    "        print ('\\nMoving to sample '+str(sample_number))\n",
    "    yield from mv(sample_selector, sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(select_sample(0, noisy=True))  # This moves a sample positioner to place Sample 0 in the beam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-cologne",
   "metadata": {},
   "source": [
    "In this tutorial, we are focused on streaming data formatted in the document-model.  As such, we're going to setup our visualization first, and then stream data in as we are measuring.  \n",
    "\n",
    "Functionally, this involve creating a figure and axes with Matplotlib, and then passing these to a callback function that will digest documents emitted by the RunEngine.\n",
    "\n",
    "When the cell below is first run, you should see a checkerboard pattern and some basic metadata in the title (sample number, and measurment number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(squeeze=False, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-imagination",
   "metadata": {},
   "source": [
    "Now we can select the sample we want and pass a <code>count</code> plan into the run engine.   \n",
    "\n",
    "<code>count</code> is the most basic acquisition plan in Bluesky.  It takes as an argument a list of detectors.  In this case, we will pass it both the <code>detector</code> and the `sample_selector` ophyd objects.  In this way, the emitted documents will automatically contain both the image data from the detector and the sample number associated with this data (important metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(select_sample(0))\n",
    "RE(count([sample_selector, detector]), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-beads",
   "metadata": {},
   "source": [
    "If everything worked, you should have seen a pattern automatically appear on the visualization, with the associated sample number (\"Sample 0\") in the image title.  This data is pulled from the streaming documents emitted by the RunEngine - we didn't have to go get them and fully process them later!\n",
    "\n",
    "Note that if you look at the immidiate output of the cell, you should see a long-string of letters and numbers.  This serves as a unique identifier (uuid) for that particular measurment that will never be repeated.  These uuids can be used as book-keeping identifiers for later data lookup, but that is beyond the scope of this tutorial.\n",
    "\n",
    "So, what happens if we measure the same sample again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(count([sample_selector, detector]), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-front",
   "metadata": {},
   "source": [
    "The <code>stream_to_figures</code> callback we have setup here contains logic to automatically average additional measurments of the same sample together.  As such, you may have noticed that the image quality improved slightly when this second measurment was performed.  The \"N_shots\" quantity in the plot title also reflects this number of shots on sample increasing.\n",
    "\n",
    "You can try re-running that cell several times if you'd like, but we can expect little visual change.  This is because sample 0 happens to be a 'strong' scatterer, and it's resultant signal-to-noise quality is good over the background.  In fact, even a single exposure produced an image with sufficient contrast to interpret scientifically.\n",
    "\n",
    "Next, let's set up a new figure, move to the next sample, and take a measurment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(squeeze=False, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes, start_at=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(select_sample(1, noisy=True))\n",
    "RE(count([sample_selector, detector]), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-triangle",
   "metadata": {},
   "source": [
    "This sample doesn't look nearly as good as the first one! It gives a weak signal (low signal-to-noise ratio). A single exposure does not produce sufficient contrast, but we can take additional exposures. The visualization above will display the average of all the exposures of this sample.\n",
    "\n",
    "We could do that by hand, re-reunning the above cell several times.  Or, we could write a custom plan to do this.  Let's go with the later as it's less tedius to manage.  Plus, we can take advantage of the ability to use plans in other plans!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_count(num_counts):\n",
    "    for i in range(num_counts):\n",
    "        print ('sequence number '+str(i))\n",
    "        yield from count([sample_selector, detector])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-grill",
   "metadata": {},
   "source": [
    "Note that we didn't have to know anything about how the guts of `count` worked, and we even made the decision to hardcode `detector` and `sample_selector` into the plan (though we wouldn't need to, it's up to how you want to write the plan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_list = RE(multi_count(5), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-clerk",
   "metadata": {},
   "source": [
    "Now the statistics on that weakly-scattering sample are starting to look better!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-impossible",
   "metadata": {},
   "source": [
    "## Acquire images for more than one sample\n",
    "\n",
    "We've already seen that samples 0 and 1 represent a strong and weakly scatterer respectively.  Let's say that based off these initial observations, we decide that the poorly-scattering sample need to be measured by some ratio (e.g. 4x) as often as good scattering samples.  We probably also want to be able to define how many total loops to complete over both samples at the desired measurement ratio.\n",
    "\n",
    "Let's write a plan!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_sample_plan(measure_ratio, tot_loops=1):\n",
    "    for i in range(tot_loops):\n",
    "        print ('\\tNow on big loop '+str(i))\n",
    "        yield from select_sample(0, noisy=True)\n",
    "        yield from count([sample_selector, detector])\n",
    "        yield from select_sample(1, noisy=True)\n",
    "        for i in range(measure_ratio):\n",
    "            yield from count([sample_selector, detector])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-bristol",
   "metadata": {},
   "source": [
    "To make the visualization easier, let's setup a callback that can display both samples at once as the data is streamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, squeeze=False, constrained_layout=True, figsize=(5, 3))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_list = RE(multi_sample_plan(4,tot_loops=2), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-renaissance",
   "metadata": {},
   "source": [
    "## Dealing with many, many samples.\n",
    "\n",
    "We have thus far been playing with just a couple of samples.  However, on the real PDF beamline at NSLS-II, we often load hundreds of different samples at one time.  And each of these samples could have very different scattering qualities!\n",
    "\n",
    "<img src=\"multi_bracket.png\" alt=\"PDF High Capacity Sample Changer\" style=\"width: 600px;\"/> \n",
    "\n",
    "let's write a custom plan to 'sweep' all samples on the simulated bracket.  For this example, we'll pretend to have 9-samples.  We would like our plan to define the total number of individual shots to be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_sweep(total_shots):\n",
    "    \"Sweep over the samples in order. Take up to `total_shots` shots.\"\n",
    "    for shot in range(total_shots):\n",
    "        yield from select_sample(shot % 9)\n",
    "        yield from count([sample_selector, detector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-concentrate",
   "metadata": {},
   "source": [
    "Our simulated detector has a simulated \"delay\", standing in for the exposure and readout time in a real detector. Here we'll speed it up a bit just so the following examples runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.delay = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = RE(sequential_sweep(total_shots=25), callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-breathing",
   "metadata": {},
   "source": [
    "You no doubt have a combination of strong and weakly scattering samples.  Note that this arrangment is random, and if you restart this Notebook, will likely be different.  You could sit down and write a custom plan, based on the scattering strength of your unique simulated samples.  However, this would get to be tedious work if performed more than once or twice.  This is where AI can help us out!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-wisdom",
   "metadata": {},
   "source": [
    "## Use `bluesky-adaptive` to let an Agent drive the experiment\n",
    "\n",
    "Here, we introduce the `bluesky-adaptive` plan.  This is a plan designed to readily interface with any sort of decision-making agent via an ask-tell interface.  More details of this plan design and implementation can be found at https://blueskyproject.io/bluesky-adaptive/\n",
    "\n",
    "We will take advantage of a plan here called `with_agent` which simplifies the interface here, but you can easily look at the details by digging into `with_agent??`\n",
    "\n",
    "### Agent 1: Naive Agent\n",
    "\n",
    "To begin with, let's use a naive sequential agent.  The goal of this agent is to, within a defined \"budget\" of time (i.e. scans), sequentially measure across each sample.  This is effectively exactly what our `sequential_sweep` plan above performed, but in the language of an agent in the `bluesky-adaptive` machinery.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adaptive_recommendations import NaiveAgent\n",
    "\n",
    "NaiveAgent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = RE(\n",
    "    with_agent(NaiveAgent(9), max_shots=70),\n",
    "    callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-wesley",
   "metadata": {},
   "source": [
    "This works well functionally, but it's not a very efficient use of our time.  After all, we would really prefer to measure the weaker-scatterers many more times than the strong scatterers, in order to built up better statistics.  However, hand-writing a plan for every set of samples is not tractable.  Let's here use an agent trained using Reinforcement Learning to accomplish this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-edwards",
   "metadata": {},
   "source": [
    "### Agent 2: Reinforcement Learning Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-tulsa",
   "metadata": {},
   "source": [
    "The details of how Reinforcement Learning (RL) works, or how we implemented it are beyond the scope of this short tutorial.  However, interested readers can find details of the method here https://iopscience.iop.org/article/10.1088/2632-2153/abc9fc. \n",
    "Essentially, the language of RL allows us to easily \"gamify\" our scientific goals.  \n",
    "\n",
    "<img src=\"gamifying_PDF.jpg\" alt=\"Gamifying the Beamline\" style=\"width: 600px;\"/> \n",
    "\n",
    "Prior to this tutorial, we trained an RL agent to develop an optimal policy that would enable for the following goals:\n",
    "\n",
    "1.)  Measure each sample initially once \n",
    "\n",
    "2.)  Repeat measurements on the samples, but collecting on weak scatterers 9x, and strong 1x.\n",
    "\n",
    "3.)  Having now built up sufficient statistics on the weak scatterers, continue to measuring each sample sequentially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-armenia",
   "metadata": {},
   "source": [
    "Note that the data collection will take slightly longer to get started as the RL agent must be loaded.  However, from the standpoint of interfacing with Bluesky, we are again using the `Bluesky-adaptive` machinery and the `with_agent` helper plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adaptive_recommendations import RLAgent\n",
    "detector.delay = 1\n",
    "unique_ids = RE(\n",
    "    with_agent(RLAgent(9, 'tf_models/bluesky-tutorial/saved_models'), max_shots=90),\n",
    "    callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-magnitude",
   "metadata": {},
   "source": [
    "Through the use of an RL agent, and `Bluesky-adaptive`, we have measured the data more efficiently than the naive sequential plan, spending more time on the samples that need extra attention!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-settle",
   "metadata": {},
   "source": [
    "### Agent 3: \"Cheating\" (Omniscient) Agent\n",
    "\n",
    "Just in case you want to try another agent, here is one who we have whispered the answer to ahead of time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, constrained_layout=True, figsize=(5, 5))\n",
    "callback = stream_to_figures(fig, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adaptive_recommendations import CheatingAgent\n",
    "\n",
    "unique_ids = RE(\n",
    "    with_agent(CheatingAgent(9), max_shots=90),\n",
    "    callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-motorcycle",
   "metadata": {},
   "source": [
    "Note the RL agent probably performed just as well as the agent which had the right answer, because it was train ahead of time how to \"play the game\" we defined through our scientific goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-safety",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
